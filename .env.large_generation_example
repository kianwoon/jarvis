# Large Generation Configuration Example
# Copy this to .env to customize large generation detection and processing

# Detection Thresholds
LARGE_GEN_STRONG_THRESHOLD=30      # Numbers >= this always trigger chunking (e.g., "generate 50 items")
LARGE_GEN_MEDIUM_THRESHOLD=20      # Numbers >= this + keywords trigger chunking (e.g., "generate 25 questions")  
LARGE_GEN_SMALL_THRESHOLD=20       # Numbers < this never trigger chunking (e.g., "generate 5 ideas")

# Scoring Parameters
LARGE_GEN_MIN_SCORE_KEYWORDS=3     # Minimum keyword score to trigger without numbers
LARGE_GEN_MIN_SCORE_MEDIUM=2       # Minimum score for medium number thresholds
LARGE_GEN_SCORE_MULTIPLIER=15      # Items per score point when no number given
LARGE_GEN_DEFAULT_COMPREHENSIVE=30 # Default items for "comprehensive" requests
LARGE_GEN_MIN_ESTIMATED=10         # Minimum estimated items

# Processing Parameters  
LARGE_GEN_MIN_CHUNKING=20          # Minimum items to trigger chunked processing
LARGE_GEN_PATTERN_WEIGHT=2         # Score boost for pattern matches
LARGE_GEN_DEFAULT_CHUNK_SIZE=15    # Items per chunk
LARGE_GEN_MAX_TARGET=500           # Maximum items to generate
LARGE_GEN_SECONDS_PER_CHUNK=45     # Estimated seconds per chunk (for progress)

# Confidence Calculation
LARGE_GEN_MAX_SCORE_CONF=5.0       # Score that gives 100% base confidence
LARGE_GEN_MAX_NUMBER_CONF=100.0    # Number that gives 100% number confidence

# Memory Management
REDIS_CONVERSATION_TTL=604800      # 7 days in seconds (7 * 24 * 3600)
REDIS_MAX_MESSAGES=50              # Messages to keep in Redis
MEMORY_MAX_MESSAGES=20             # Messages to keep in memory
CONVERSATION_HISTORY_DISPLAY=10    # Messages to show in formatted history

# Example Usage:
# - To make detection more sensitive: Lower LARGE_GEN_STRONG_THRESHOLD to 20
# - To make detection less sensitive: Raise LARGE_GEN_MIN_SCORE_KEYWORDS to 4
# - To increase chunk size: Set LARGE_GEN_DEFAULT_CHUNK_SIZE=20
# - To keep more conversation history: Set REDIS_MAX_MESSAGES=100