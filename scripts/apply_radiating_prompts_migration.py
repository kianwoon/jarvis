#!/usr/bin/env python3
"""
Script to apply the radiating prompts migration and verify the system is working correctly.
This script:
1. Applies the database migration to add prompts to settings
2. Verifies the prompts are accessible through the cache
3. Tests that the radiating system can use the prompts
"""

import sys
import os
import json
import asyncio
from datetime import datetime

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.db import SessionLocal, Settings as SettingsModel
from app.core.radiating_settings_cache import (
    reload_radiating_settings,
    get_radiating_prompts,
    get_prompt,
    update_prompt,
    reload_radiating_prompts
)


def apply_migration():
    """Apply the migration to add radiating prompts to the database."""
    print("üìù Applying radiating prompts migration...")
    
    db = SessionLocal()
    try:
        # Check if radiating settings already exist
        radiating_row = db.query(SettingsModel).filter(SettingsModel.category == 'radiating').first()
        
        if radiating_row:
            print("‚úÖ Radiating settings already exist in database.")
            # Update with prompts if they don't exist
            if 'prompts' not in radiating_row.settings:
                print("üìå Adding prompts to existing radiating settings...")
                radiating_row.settings['prompts'] = get_default_prompts()
                radiating_row.updated_at = datetime.now()
                db.commit()
                print("‚úÖ Prompts added to existing settings.")
        else:
            # Create new radiating settings with prompts
            print("üìå Creating new radiating settings with prompts...")
            settings_data = get_default_settings_with_prompts()
            radiating_row = SettingsModel(
                category='radiating',
                settings=settings_data,
                updated_at=datetime.now()
            )
            db.add(radiating_row)
            db.commit()
            print("‚úÖ Radiating settings with prompts created successfully.")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error applying migration: {e}")
        db.rollback()
        return False
    finally:
        db.close()


def get_default_prompts():
    """Get the default prompts structure."""
    return {
        "entity_extraction": {
            "discovery_comprehensive": """You are analyzing a query about MODERN LLM-ERA technologies (2023-2024 era).
Focus on technologies actually used for building LLM-powered applications TODAY.
Identify ALL relevant entity types for a COMPREHENSIVE extraction {domain_context}.

Query/Text: {text}

CRITICAL: Focus on MODERN AI/LLM technologies, NOT legacy ML tools!
Modern means: LangChain, Ollama, vector databases, LLM frameworks, RAG systems
NOT legacy: scikit-learn, Keras (outdated for LLM apps)

Return as JSON with MANY specific entity types...""",
            
            "discovery_regular": """Analyze this text and identify the types of entities present {domain_context}.
Do not use generic types like "Person", "Organization", "Location" unless they truly fit.
Instead, discover domain-specific entity types that best describe the content.

Text: {text}

Return as JSON...""",
            
            "extraction_comprehensive": """You are an expert on MODERN LLM-ERA technologies (2023-2024 era).
The user is asking for a COMPREHENSIVE list of entities related to their query.

{domain_context}
{additional_context}

Query/Text: {text}

Return as JSON array with AT LEAST 30 entities...""",
            
            "extraction_regular": """Extract all important entities from this text.
{domain_context}
{additional_context}
{type_guidance}

Text: {text}

Return as JSON array..."""
        },
        
        "relationship_discovery": {
            "llm_discovery": """You are an expert in technology, AI, ML, software systems, cloud computing, databases, and business relationships.

Analyze these entities and discover ALL meaningful relationships between them based on your comprehensive knowledge:

ENTITIES:
{entity_list}

RELATIONSHIP TYPES TO USE (MUST use these specific types):
{relationship_types}

Return a JSON object with comprehensive relationships...""",
            
            "relationship_analysis": """Analyze the relationships between these entities {domain_context}:

Entities:
{entity_list}

Text:
{text}

Return as JSON array...""",
            
            "implicit_relationships": """Analyze these entities and infer implicit relationships {domain_context}:

{entities_json}

Return as JSON array of implicit relationships..."""
        },
        
        "query_analysis": {
            "entity_extraction": """Extract key entities from the following query. For each entity, identify:
1. The entity text
2. The entity type (Person, Organization, Location, Concept, Event, etc.)
3. Confidence score (0.0 to 1.0)

Query: {query}

Return as JSON array...""",
            
            "intent_identification": """Identify the primary intent of this query. Choose from:
- EXPLORATION: Broad discovery queries
- CONNECTION_FINDING: Finding relationships between things
- COMPREHENSIVE: Deep, thorough information gathering
- SPECIFIC: Targeted, narrow queries
- COMPARISON: Comparing multiple entities
- TEMPORAL: Time-based queries
- CAUSAL: Cause-effect relationships
- HIERARCHICAL: Parent-child or part-whole relationships

Query: {query}
Entities found: {entities}

Return only the intent type name.""",
            
            "domain_extraction": """Identify the knowledge domains relevant to this query.
Examples: Technology, Business, Science, Medicine, Finance, Education, etc.

Query: {query}

Return as JSON array of domain names (max 5)...""",
            
            "temporal_extraction": """Extract temporal context from this query if present.
Look for: time periods, dates, relative times (latest, recent, current), etc.

Query: {query}

Return as JSON or null if no temporal context..."""
        },
        
        "expansion_strategy": {
            "semantic_expansion": """Find semantically related terms and entities for:
Entity: {entity}
Type: {entity_type}
{domain_context}

Return as JSON...""",
            
            "concept_expansion": """Identify related concepts and topics for this query:
Query: {query}
{domain_context}

Return as JSON array of related concepts (max 5)...""",
            
            "hierarchical_expansion": """Find hierarchical relationships for:
Entity: {entity}
Type: {entity_type}

Return as JSON..."""
        }
    }


def get_default_settings_with_prompts():
    """Get default radiating settings including prompts."""
    return {
        "enabled": True,
        "default_depth": 3,
        "max_depth": 5,
        "relevance_threshold": 0.7,
        "expansion_strategy": "adaptive",
        "cache_ttl": 3600,
        "traversal_strategy": "hybrid",
        "max_entities_per_hop": 10,
        "relationship_weight_threshold": 0.5,
        "prompts": get_default_prompts(),
        "query_expansion": {
            "enabled": True,
            "max_expansions": 5,
            "confidence_threshold": 0.6,
            "preserve_context": True,
            "expansion_method": "semantic"
        },
        "extraction": {
            "entity_confidence_threshold": 0.6,
            "relationship_confidence_threshold": 0.65,
            "enable_universal_discovery": True,
            "max_entities_per_query": 20,
            "max_relationships_per_query": 30
        }
    }


def verify_prompts_accessible():
    """Verify that prompts are accessible through the cache system."""
    print("\nüîç Verifying prompts are accessible...")
    
    try:
        # Reload settings from database
        settings = reload_radiating_settings()
        
        # Check if prompts exist
        prompts = get_radiating_prompts()
        if not prompts:
            print("‚ùå No prompts found in settings!")
            return False
        
        print(f"‚úÖ Found {len(prompts)} prompt categories:")
        for category in prompts:
            print(f"   - {category}: {len(prompts[category])} prompts")
        
        # Test retrieving specific prompts
        test_cases = [
            ('entity_extraction', 'discovery_comprehensive'),
            ('relationship_discovery', 'llm_discovery'),
            ('query_analysis', 'entity_extraction'),
            ('expansion_strategy', 'semantic_expansion')
        ]
        
        print("\nüìã Testing specific prompt retrieval:")
        for category, prompt_name in test_cases:
            prompt = get_prompt(category, prompt_name)
            if prompt:
                print(f"   ‚úÖ {category}/{prompt_name}: {len(prompt)} characters")
            else:
                print(f"   ‚ùå {category}/{prompt_name}: NOT FOUND")
                return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error verifying prompts: {e}")
        return False


async def test_radiating_system():
    """Test that the radiating system can use the prompts from settings."""
    print("\nüß™ Testing radiating system with database prompts...")
    
    try:
        # Import the modules that use prompts
        from app.services.radiating.extraction.universal_entity_extractor import UniversalEntityExtractor
        from app.services.radiating.query_expansion.query_analyzer import QueryAnalyzer
        
        # Test entity extraction
        print("   Testing entity extraction...")
        extractor = UniversalEntityExtractor()
        test_text = "LangChain is a framework for building LLM applications using OpenAI and vector databases like Milvus."
        entities = await extractor.extract_entities(test_text)
        print(f"   ‚úÖ Entity extraction working: found {len(entities)} entities")
        
        # Test query analysis
        print("   Testing query analysis...")
        analyzer = QueryAnalyzer()
        test_query = "What are the latest AI frameworks for building RAG systems?"
        analysis = await analyzer.analyze_query(test_query)
        print(f"   ‚úÖ Query analysis working: intent={analysis.intent.value}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Error testing radiating system: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_prompt_update():
    """Test updating a prompt and verifying the change."""
    print("\nüîÑ Testing prompt update functionality...")
    
    try:
        # Get original prompt
        original = get_prompt('query_analysis', 'entity_extraction')
        print(f"   Original prompt length: {len(original)} characters")
        
        # Update the prompt
        new_prompt = "TEST PROMPT: Extract entities from {query}"
        update_prompt('query_analysis', 'entity_extraction', new_prompt)
        print("   Updated prompt in settings")
        
        # Reload and verify
        reload_radiating_prompts()
        updated = get_prompt('query_analysis', 'entity_extraction')
        
        if updated == new_prompt:
            print("   ‚úÖ Prompt update successful")
            
            # Restore original
            update_prompt('query_analysis', 'entity_extraction', original)
            reload_radiating_prompts()
            print("   ‚úÖ Original prompt restored")
            return True
        else:
            print("   ‚ùå Prompt update failed")
            return False
            
    except Exception as e:
        print(f"   ‚ùå Error testing prompt update: {e}")
        return False


async def main():
    """Main function to run all migration and verification steps."""
    print("=" * 60)
    print("üöÄ Radiating Prompts Migration Tool")
    print("=" * 60)
    
    # Step 1: Apply migration
    if not apply_migration():
        print("\n‚ùå Migration failed. Exiting.")
        return 1
    
    # Step 2: Verify prompts are accessible
    if not verify_prompts_accessible():
        print("\n‚ùå Prompts verification failed. Exiting.")
        return 1
    
    # Step 3: Test radiating system
    if not await test_radiating_system():
        print("\n‚ö†Ô∏è  Radiating system test failed (this may be OK if LLM is not available)")
    
    # Step 4: Test prompt updates
    if not test_prompt_update():
        print("\n‚ùå Prompt update test failed. Exiting.")
        return 1
    
    print("\n" + "=" * 60)
    print("‚úÖ All migration steps completed successfully!")
    print("=" * 60)
    print("\nüìå Next steps:")
    print("1. The radiating prompts are now stored in the database")
    print("2. You can update prompts through the settings UI")
    print("3. Changes will take effect immediately without restart")
    print("4. All 13 hardcoded prompts have been moved to database")
    
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)